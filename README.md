# Project Explanation
## The goal of this project was to determine the impact of adding AI generated images to datasets who lack a sufficient number of training images. A stop sign detection, and flower classification model were used to test the hypothesis of whether adding AI generated images from DallE would be helpful or hurt model performance on test image datasets. The detection task was built around detecting stop sings in google street view images in a custom dataset, and the classification used a Kaggle dataset of five flower types. Four total models were then built.   Classification with AI images, classification without AI images, detection with AI images, and detection without AI images. Labeling was completed in Roboflow to ease on the time spent labeling images and prepping folder for training. Training and model inference was completed in Google Colab. Lastly, model performance was then compared to draw conclusions from.

## Note that DallE and Roboflow require my personal API key which can be sent on request (they are not in GitHub or Colab). 

#
# Links

## Video Presentation
#### https://www.youtube.com/watch?v=6JrdE4QdRCs

## Video Demo
#### 

## Report
#### https://drive.google.com/file/d/1gPjjgh5AD3-DNYAm3S0UU_0u-821FRaX/view?usp=drive_link

## PowerPoint Presentation
#### https://drive.google.com/file/d/1Vr9mBKrin27o6n9q0k64kJiM3Lq7kKA_/view?usp=drive_link

## Dataset (images folder)
#### https://drive.google.com/drive/folders/10PB3pAUjPRphave760XDYh47mLhVydeQ?usp=drive_link (google drive for images and full .ipynb for training and inference)
#### Image Dataset specifcially: https://drive.google.com/drive/folders/1j-Z9tDGHWMYl3bkZv-S5IViQyOU1tV-t?usp=drive_link

## Full .ipynb for Training and Inference
#### https://drive.google.com/drive/folders/10PB3pAUjPRphave760XDYh47mLhVydeQ?usp=drive_link (google drive for images and full .ipynb for training and inference)

# 
# Github and Drive File Explanation - https://github.com/jrmazure/ece5831-2024-final-project

## Summary ipynb file - final-project.ipynb
#### This file shows all python and ipynb files in one for quick viewing and demo pruposes. It can also be found at https://drive.google.com/drive/folders/10PB3pAUjPRphave760XDYh47mLhVydeQ?usp=drive_link with full putput file at (https://drive.google.com/drive/folders/1YL10vvFbnQ0IFBt3qcmYRlPxShJGFYF5?usp=drive_link) 


## Images Folder on Google Drive
#### A classification and detection folder exist for each use-case (stop sign detection and flower classification)
#### Classification contains the original dataset images downloaded from Kaggle (Original_Dataset), DallE downloaded images (DallE_Download), and the AI and non AI folders downloaded form Roboflow (for train/validation/test breakdown)
#### Detection contains the original custom dataset (Original_Dataset), raw images for upload to DallE (DallE_Raw), masked images for upload to DallE (DallE_Mask), masked images with human placement for DallE (DallE_Mask_Directed), downloaded images from DallE editing (DallE_Download), and lastly the AI and non AI folder downloaded from Roboflow (for train/validation/test breakdown)

## Colab notebooks for training and inference
#### The .ipynb files in the notebook directory should be opened in google colab to view full outputs and those notebooks can be found in the following link: https://drive.google.com/drive/folders/10PB3pAUjPRphave760XDYh47mLhVydeQ?usp=drive_link. These files were used to train the model and run inferences on the model. All models were labeled using Roboflow, and image datasets were then imported into Colab using the Roboflow API. Models were then trained using Transfer learning from YOLOV11 for detection and YOLOV8 for classification. Inferences were then ran on every test image to gather image statistics. The fully executed .ipyn files were executed wiht a google acocunt using a paid subscription. To see full execution output, the following Google Drive link should be used (https://drive.google.com/drive/folders/1YL10vvFbnQ0IFBt3qcmYRlPxShJGFYF5?usp=drive_link) 

## Ipynb's used for DallE edit generation
#### uploadImagesForDallEEdit_Classification.ipynb - this notebook takes a flower name, inserts that name into an array of DallE image prompts, and then requests and image from DallE 3 to be generated from a random selection of potential prompts. The URLs generated by DallE are used to download the image file to be used for image training. This is iterated across as many times as desired to obtain images.
#### uploadImagesForDallEEdit_Detect.ipynb - this notebook takes the original image path, and mask image path, and then uploads those images to DallE with a randomly selected prompt (pertaining to a stop sign being within a street view). The URLS obtained are then used to download an image that can be used in a training dataset.  
#### createDirectedMask.ipynb - this notebook takes an input and an output path, as well as position and size information for a desired png alpha mask. These alpha masks are required to obtain image edits from DallE2. Masks sizes are not considering the user is controlling the size specifically and can see DallE model performance. Images are saved to DallE_Mask_Directed folder with the same name as the original upload to easily pair them during DallE upload. 
#### createRandomMask.ipynb - this notebook takes an input and an output path and generates random png alpha masks throughout the images. These alpha masks are required to obtain image edits from DallE2. Masks sizes are constrained due to DallE poor performance on very small and very large areas for the dataset. Images are saved to DallE_Mask folder with the same name as the original upload to easily pair them during DallE upload. 


